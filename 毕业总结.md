## 背景
参加大模型应用的训练营是因为AI的热度这几年一直持续高涨，在公司内也涌现越来越多AI应用，而自身本是做关于数据服务软件的前后端开发的，自然想加入这波浪潮。最开始对AI、ML并没有什么了解，一直以为要有相当的数学知识才能做相关领域的东西，随着学习这个课程的深入，明白到作为软开想要进入AI行业，门槛没有想象的高（当然，有相关数学知识能让职业生涯的天花板更高）。但作为想入行的新人，这个训练营很好的让我迈出了第一步。

## 课程内容深入浅出
从一开始AIML的历史、大模型的历史，到最近出圈的transformer架构、self-attention机制，老师都尽量压缩在2周的课内，让大家先有概念，我认为这部分总体还是很有信息量的，但是对于self-attention机制的部分Q, K, V的解释觉得可以再形象或者清晰一些。
对于后来openAI, embedding, langchain, 以及它们对应的实战项目，认为是这门课很值的地方。Jupyter Notebook里的代码和解释也很详细，除去langchain版本的原因，notebook里的代码基本能跑通，也让我对实际上手和探索AI应用有了更多的信心。我认为课程中，就是老师在视频里布置的作业（notebook里的作业）还是很合适的，可以适当的回顾那节课的内容。对于课程里每隔几周必交的作业，虽然作业内容不算困难，但是配置环境、安装包、跑起来这个过程也要花不少时间，建议极客是否可以考虑给学员提供云的运行环境，特别是针对这种大模型的课程。

## 收获
我认为这门课带领我很好的入门，学会了怎么调用OpenAI、智谱的大模型，怎么用langchain的框架实现更为复杂一些的模型应用，之后在开发大模型应用的时候，也有这些代码和资料可以参考。除了技术上的，直播时老师面对同学们的回答，也更多从一个更为实际和综合的角度出发，首先要找到关键的痛点，可能更多是业务上的行政上的问题，新技术可以增效，但没法从根本解决设计本身的问题。